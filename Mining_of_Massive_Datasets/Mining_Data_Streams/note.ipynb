{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Mining Data Streams\n",
    "============\n",
    "\n",
    "Data:    \n",
    "1. database   \n",
    "2. stream:     \n",
    "    + lost forever if the data arrived is not processed immediately or stored.    \n",
    "    + the data arrives so rapidly that it isn't feasible to store all.   \n",
    "    \n",
    "    solution: summarization     \n",
    "        + sample/filter, then estimate     \n",
    "        + fixed-length \"window\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 The Stream Data Model\n",
    "\n",
    "Examples of Steam Sources:   \n",
    "\n",
    "+ Sensor Data:      \n",
    "  Deploy a million sensors    \n",
    "  \n",
    "+ Image Data:     \n",
    "  satellites, surveilance camera\n",
    "\n",
    "+ Internet and Web Traffic\n",
    "\n",
    "![Fig 4.1: A data-stream_management system](files/res/figure_4_1.png)\n",
    "\n",
    "##### 4.1.3 Stream Queries\n",
    "two ways:\n",
    "\n",
    "1. standing queries     \n",
    "   preset, permanetly execting, and produce outputs at appropriate times.    \n",
    "\n",
    "2. ad-hoc queries    \n",
    "   a question asked once about the current state of a steam or streams.    \n",
    "   + a common sample approach is to store a **sliding windows** of each stream in the working store.\n",
    "  \n",
    "  \n",
    "**generalizations** about stream algorithms:\n",
    "\n",
    "1. Often, an **approximate answer** is much more **efficient** than an **exact solution**.\n",
    "\n",
    "2. **hash function** introduces useful **randomness** intho the algorithm's behavior $\\to$ approximate answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sampling Data in a Stream\n",
    "\n",
    "extract reliable samples from a stream:    \n",
    "select $S \\subset B$, $\\, s.t. \\, E[f(S)] = E[f(B)]$.\n",
    "\n",
    "Example   \n",
    "Prob: What fraction of the typical user's queries were repeated over the past month?     \n",
    "\n",
    "given: a user has issued $s$ search queries one time, $d$ queries two times, and no queires more than twice.\n",
    "\n",
    "solutions:\n",
    "\n",
    "- _REAL_: $$tf = \\frac{d}{s+d}$$\n",
    "\n",
    "- _BAD_: store 1/10 th of the stream **elements**.    \n",
    "  + for s: $1/10 s$ one time    \n",
    "  + for d:      \n",
    "    $(1/10)*(1/10)*d = 1/100 d$ two times,      \n",
    "    $1/10*9/10 + 9/10*1/10 d = 18/100d$ one time.\n",
    "  + calc: \n",
    "  $$\\hat{tf} = \\frac{1/100d}{1/10s + 1/100d + 18/100d} = \\frac{d}{10s + 19d}$$\n",
    "\n",
    "- _GOOD_: pick 1/10th of the **users** and take all their searches for the sample.    \n",
    "  $$\\hat{tf} = \\frac{d}{s+d}$$     \n",
    "  \n",
    "  sample: **hash**    \n",
    "  obtain a sample consisting of any rational fraction $a/b$ of the users by hashing user names to $b$ buckets. Add the search query to the sample if the hash value is less than $a$.\n",
    "  \n",
    "  **The General Sampling Problem**   \n",
    "  Our steam $x$ consists of tuples with $n$ components $\\{x_n\\}$(eg: user, query, time), and a subset of the components are the _key_ components $x_k$(eg: user).     \n",
    "  To take a sample of size $a/b$, we hash the _key_ value $h(x_k)$ for each tuple to $b$ buckets, and accept the tuple if $h(x_k) < a$.\n",
    "  \n",
    "  **varying the sample size**    \n",
    "  storage is limited, while users/queries grows as time goes on  ==> decrease the select fraction $a/b$.    \n",
    "  \n",
    "  solution:   \n",
    "  1. $h(x) = \\{0, 1, \\dots, B-1\\}$, $B$ is sufficient large.    \n",
    "  2. maintain a threshold $t$, we accept when $h(x) < t$.       \n",
    "  3. $t = t - 1$ if the allotted space is exceeded. remove all samples $h(x) = t$.    \n",
    "     [opt] efficient:   \n",
    "     + lower $t$ by more than 1.    \n",
    "     + maintaining an index on the hash value to find all those tuples quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
