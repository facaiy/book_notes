{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Finding Similar Items\n",
    "===================\n",
    "Problem:    \n",
    "+ \"similar\": finding sets with a relatively large intersection.    \n",
    "    - shingling    \n",
    "    - minhashing    \n",
    "+ too many pairs of items to test     \n",
    "    - locality-sentitive hashing\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Applications of Near-Neighbor Search\n",
    "\n",
    "The *Jaccard Similarity* of sets $S$ and $T$:\n",
    "\\begin{equation}\n",
    "SIM(S,T) = \\frac{| S \\cup T |}{| S \\cap T |}\n",
    "\\end{equation}\n",
    "\n",
    "##### Similar-sets Problem\n",
    "1. Similar Documents    \n",
    "In many applicatons, the documents are not identical, yet they share large portions of their text.    \n",
    "eg: Plagiarism, Mirror Pages, Articles from the Same Source.     \n",
    "2. Collaborative Filtering(Similar Tastes)    \n",
    "eg: \n",
    "    + Online Purchases    \n",
    "    + Movie Ratings     \n",
    "        When data is not binary:           \n",
    "        - Ignore low-rated customer/movie pairs    \n",
    "        - \"liked\" VS \"hated\"     \n",
    "        - 1-to-5-starts, put it in a set $n$ times. <= _Jaccard similarity for bags_\n",
    "            \n",
    "##### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:set([1, 2, 3, 4]), b:set([2, 3, 5, 7]), SIM:0.333\n",
      "a:set([1, 2, 3, 4]), b:set([2, 4, 6]), SIM:0.400\n",
      "a:set([2, 3, 5, 7]), b:set([2, 4, 6]), SIM:0.167\n"
     ]
    }
   ],
   "source": [
    "#Exercise 3.1.1\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "data = [\n",
    "    set([1, 2, 3, 4]),\n",
    "    set([2, 3, 5, 7]),\n",
    "    set([2, 4, 6]),\n",
    "]\n",
    "\n",
    "def Jaccard_similarity_calc(set_a, set_b):\n",
    "    \"\"\"calculate the Jaccard similarity of two sets\n",
    "    \n",
    "    res = \\frac{a \\cap b}{a \\cup b}\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(set_a, set), '{} is not a set'.format(set_a)\n",
    "    assert isinstance(set_b, set), '{} is not a set'.format(set_b)\n",
    "    \n",
    "    logging.debug('a:{}, b:{}'.format(set_a, set_b))\n",
    "    logging.debug('inter:{}, union:{}'.format(set_a.intersection(set_b), set_a.union(set_b)))\n",
    "    return len(set_a.intersection(set_b)) / len(set_a.union(set_b))\n",
    "\n",
    "for comb in list(itertools.combinations(range(3),2)):\n",
    "    set_a, set_b = data[comb[0]], data[comb[1]]\n",
    "    print('a:{}, b:{}, SIM:{:.3f}'.format(set_a, set_b, Jaccard_similarity_calc(set_a, set_b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:[1, 1, 1, 2], b:[1, 1, 2, 2, 3], JbSIM:0.333\n",
      "a:[1, 1, 1, 2], b:[1, 2, 3, 4], JbSIM:0.250\n",
      "a:[1, 1, 2, 2, 3], b:[1, 2, 3, 4], JbSIM:0.333\n"
     ]
    }
   ],
   "source": [
    "#Exercise 3.1.2\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "data = [\n",
    "    [1, 1, 1, 2],\n",
    "    [1, 1, 2, 2, 3],\n",
    "    [1, 2, 3, 4],\n",
    "]\n",
    "\n",
    "def Jaccard_bag_similarity_calc(a, b):\n",
    "    \"\"\"calculate the Jaccard bag similarity of two sets\n",
    "    \n",
    "    see page 76, movie ratings 3.\n",
    "    intersecton = min(times of element in the two sets)\n",
    "    union = sum of length of the two sets\n",
    "    res = intersection / union\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import Counter\n",
    "    \n",
    "    count_a = Counter(a)\n",
    "    count_b = Counter(b)\n",
    "    logging.debug('count_a:{}\\n count_b:{}'.format(count_a,count_b))\n",
    "    \n",
    "    inter = [min(count_a[x], count_b[x]) for x in count_a if x in count_b]\n",
    "    logging.debug('intersection:{}'.format(inter))\n",
    "    \n",
    "    return sum(inter) / (len(a) + len(b))\n",
    "    \n",
    "for comb in list(itertools.combinations(range(3),2)):\n",
    "    set_a, set_b = data[comb[0]], data[comb[1]]\n",
    "    print('a:{}, b:{}, JbSIM:{:.3f}'.format(set_a, set_b, Jaccard_bag_similarity_calc(set_a, set_b)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_exercise 3.1.3_\n",
    "\n",
    "引理：    \n",
    "定义\n",
    "\\begin{equation}\n",
    "    I\\{A\\} = \\begin{cases}\n",
    "                 1 & \\text{if $A$ occurs.} \\\\\n",
    "                 0 & \\text{otherwise.}\n",
    "             \\end{cases}\n",
    "\\end{equation}\n",
    "令 $X_A = I\\{A\\}$，则有 $E[X_A] = \\sum I\\{A\\}P[A] = P[A]$\n",
    "\n",
    "\n",
    "令 $x_i$ 表示 S 和 T 中有 $i$ 个相同元素，则：\n",
    "\\begin{align}\n",
    "    E[x_i] & = P[\\text{S 和 T 中有 $i$ 个相同元素}] \\\\\n",
    "           & = \\frac{C_n^i \\, C_{n-i}^{2(m-i)}}{C_n^{m} C_n^{m}}\n",
    "\\end{align}\n",
    "\n",
    "所以\n",
    "\\begin{align}\n",
    "    E[J] & = \\sum_{i=0}^m E[x_i] \\, J_i \\\\\n",
    "         & = \\frac{\\sum_{i=0}^m \\, C_n^i \\, C_{n-i}^{2(m-i)} \\, \\frac{i}{2(m-i)}}{C_n^{m} C_n^{m}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "`#todo 推导最终式`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Shingling of Documents\n",
    "\n",
    "**k-shingle**: any substring of length $k$ found within the document.  \n",
    "+ variation: set -> bag\n",
    "+ multiple white-space => one white-space\n",
    "+ choosing k    \n",
    "    - **large enough** that prob. of **any given shingle** appearing in **any given document** is **low**.    \n",
    "      k 越大，对相似性要求越高\n",
    "    - estimate the number of k-shingles as $20^k$, instead of 27 char, 因为各个字符的出现频率并非一致\n",
    "    - in general,    \n",
    "      email: k = 5;     \n",
    "      large documents, such as research articles: k = 9  \n",
    "+ stop words, such as \"and\", \"you\", \"to\"    \n",
    "    - ignore them in many application\n",
    "    - **\"stop words + two words\"** used as shingle in finding similar **news articles**.\n",
    "      \n",
    "**hashing Shingles**: h(shingle) = bucket\n",
    "+ 9-shingles, then hash to 4 char > 4-shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3.3: ['ab', 'bc', 'cd', 'da', 'bd']\n",
      "other example: ['he', 'el', 'll', 'lo', 'o ', ' i', 'i ', ' m', 'm ', ' s', 'so']\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def to_alphanumeric_string(s):\n",
    "    \"\"\"remove any non-alphanumeric characte in string s.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    s = s.lower()\n",
    "    s = re.sub('\\W', ' ', s)\n",
    "    logging.debug('after: del special char: {}'.format(s))\n",
    "    s = re.sub('\\s+', ' ', s).strip()\n",
    "    logging.debug('after: del multiple whitespace: {}'.format(s))\n",
    "    \n",
    "    return s\n",
    "\n",
    "def k_shingle_extrac(document, k):\n",
    "    \"\"\"extract all k-shingles from document.\n",
    "    \n",
    "    \"\"\"\n",
    "    document = to_alphanumeric_string(document)\n",
    "\n",
    "    assert len(document) >= k, 'k should be less than the length of document'\n",
    "    \n",
    "    k_shingles = []\n",
    "    while len(document) >= k:\n",
    "        shingle = document[0:k]\n",
    "        if shingle not in k_shingles:\n",
    "            k_shingles.append(shingle)\n",
    "        document = document[1:]\n",
    "        \n",
    "    return k_shingles\n",
    "\n",
    "\n",
    "print('Example 3.3: {}'.format(k_shingle_extrac('abcdabd', 2)))\n",
    "print('other example: {}'.format(k_shingle_extrac(\"Hello, I'm So-So.  \", 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 3-shingles:['the', 'he ', 'e m', ' mo', 'mos', 'ost', 'st ', 't e', ' ef', 'eff']\n"
     ]
    }
   ],
   "source": [
    "#exercise 3.2.1\n",
    "\n",
    "data = \"The most effective way to represent documents as sets, for the purpose of iden- tifying lexically similar documents is to construct from the document the set of short strings that appear within it. \"\n",
    "\n",
    "print('first 10 3-shingles:{}'.format(k_shingle_extrac(data,3)[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop-shingles:['the most effective', 'to represent documents', 'as sets for', 'for the purpose', 'the purpose of', 'of iden tifying', 'is to construct', 'to construct from', 'from the document', 'the document the', 'the set of', 'of short strings', 'that appear within', 'it']\n"
     ]
    }
   ],
   "source": [
    "#exercise 3.2.2\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def stopwords_shingles_extract(document, k):\n",
    "    \"\"\"extract the stopwords-shingle.\n",
    "    \n",
    "    stropwords-shingle = stop-words + k words\n",
    "    \"\"\"\n",
    "    stop_words_list = ['the', 'you', 'to', 'as', 'for', 'of', 'is', 'that', 'it', 'from']\n",
    "    \n",
    "    document = to_alphanumeric_string(document)\n",
    "    document = document.split()\n",
    "    logging.debug('split:{}'.format(document))\n",
    "    \n",
    "    shingles = []\n",
    "    k = k + 1 #len(shingle) = 1 stop-word + k words\n",
    "    while(document):\n",
    "        try:\n",
    "            logging.debug('check:{}'.format(document[0]))\n",
    "            if document[0] in stop_words_list:\n",
    "                shingle = ' '.join(document[0:k])\n",
    "                logging.debug('hit: {}'.format(shingle))\n",
    "                \n",
    "                if shingle not in shingles:\n",
    "                    shingles.append(shingle)\n",
    "                    \n",
    "        except IndexError:\n",
    "            logging.debug('Index Error: no of char:{}, k: {}'.format(len(document), k))\n",
    "            k = len(document)\n",
    "            continue\n",
    "            \n",
    "        document = document[1:]\n",
    "    \n",
    "    return shingles\n",
    "\n",
    "print('stop-shingles:{}'.format(stopwords_shingles_extract(data, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#exercise 3.2.3`\n",
    "\n",
    "k-shingles 最大数量：所有提取的 shingle 均不同    \n",
    "故从左向右依次取片，有：     \n",
    "the largest number = n - (k - 1) = n - k + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Similarity-Preserving Summaries of Sets\n",
    "\n",
    "##### Matrix Representation of Sets:  \n",
    "(r,c) = 1: the element for row r is a member of the set for column c.  \n",
    "(r,c) = 0: otherwise  \n",
    "\n",
    "+ matrices are almost always **sparse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  S2  S3  S4\n",
       "a   1   0   0   1\n",
       "b   0   0   1   0\n",
       "c   0   1   0   1\n",
       "d   1   0   1   1\n",
       "e   0   0   1   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 3.6\n",
    "\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "my_database = ['a', 'b', 'c', 'd', 'e']\n",
    "my_features_dict = {\n",
    "    'S1':['a', 'd'],\n",
    "    'S2':['c'],\n",
    "    'S3':['b', 'd', 'e'],\n",
    "    'S4':['a', 'c', 'd']\n",
    "    }\n",
    "\n",
    "def matrix_representation_create(database, features_dict):\n",
    "    \"\"\"create the matrix representation of one database.\n",
    "    \n",
    "    \"\"\"\n",
    "    matrix_ = np.zeros((len(database), len(features_dict)), dtype=np.int)\n",
    "    matrix = pd.DataFrame(matrix_, index=database, columns=sorted(features_dict.keys()))\n",
    "    \n",
    "    for feature_name, values in features_dict.iteritems():\n",
    "        for value in values:\n",
    "            matrix.loc[value, feature_name] = 1\n",
    "            \n",
    "    return matrix\n",
    "    \n",
    "    \n",
    "my_matrix = matrix_representation_create(my_database, my_features_dict)\n",
    "my_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minhashing\n",
    "\n",
    "_target_: sets of shingles are large =====> much smaller representations called \"**signatures**\"\n",
    "\n",
    "**minhash**\n",
    "1. pick a permutation of the rows\n",
    "2. h(columu c) = the row which has the first \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h1</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1 S2 S3 S4\n",
       "h1  a  c  b  a"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 3.7\n",
    "\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def minhash(matrix, row_orders):\n",
    "    \"\"\"calculate the minhash value of matrix according to element permutation in Fig 3.3.\n",
    "    \n",
    "    \"\"\"\n",
    "    hash_fun_names = ['h{}'.format(i) for i in range(1, len(row_orders)+1)]\n",
    "    hash_table = pd.DataFrame(np.zeros((len(row_orders), matrix.shape[1])), index=hash_fun_names, columns=matrix.columns)\n",
    "\n",
    "    for row_order, hash_fun_name in zip(row_orders, hash_fun_names):\n",
    "        matrix_p = matrix.loc[row_order,:]\n",
    "        logging.debug('after permutation: \\n{}'.format(matrix_p))\n",
    "    \n",
    "        for c in matrix_p.columns:\n",
    "            first_one_index = next((i for i, x in enumerate(matrix_p.loc[:,c]) if x), None)\n",
    "            hash_table.loc[hash_fun_name, c] = row_order[first_one_index]\n",
    "\n",
    "    return hash_table\n",
    "\n",
    "\n",
    "minhash(my_matrix, [['b', 'e', 'a', 'd', 'c']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minhash and Jaccard Similarity**: $P[h(S1) = h(S2)] = SIM(S1, S2)$\n",
    "\n",
    "*Proof*:\n",
    "rows can be divided into three classes:\n",
    "\n",
    "+ Type X rows have 1 in both columns (means both S1 and S2 have these features)\n",
    "+ Type Y rows have 1 in either S1 or S2\n",
    "+ Type Z rows have 0 in both columns (means both S1 and S2 don't have them)\n",
    "\n",
    "\\begin{align}\n",
    "    | S1 \\cap S2 | & = len(X) \\\\\n",
    "    | S1 \\cap S2 | & = len(X+Y) \\\\\n",
    "    SIM(S1, S2) &= \\frac{len(X)}{len(X+Y)}\n",
    "\\end{align}\n",
    "\n",
    "randomly permute rows, there is at least one colunm whose value is 1:\n",
    "$$ P[h(S1) = h(S2)] = \\frac{len(x)}{len(X+Y)} $$\n",
    "\n",
    "**minhash signature**:   \n",
    "use vector $[h_1(S), h_2(S), ... , h_n(S)]$ to represent matrix M    \n",
    "namely, reduce the dim: columns(M) -----> n\n",
    "\n",
    "**Computing Minhash Signatures**   \n",
    "picking a random permutation of large rows and find its hash value both are **time-consuming** ==> simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix:\n",
      "   S1  S2  S3  S4\n",
      "0   1   0   0   1\n",
      "1   0   0   1   0\n",
      "2   0   1   0   1\n",
      "3   1   0   1   1\n",
      "4   0   0   1   0\n",
      "\n",
      "minhash: 5dim -> 2dim \n",
      "       true hash res:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   0   1\n",
      "h2   0   2   0   0\n",
      "\n",
      "Minhashing\n",
      "S1-S2 minhash:0.000 true SIM:0.000\n",
      "S1-S3 minhash:0.500 true SIM:0.250\n",
      "S1-S4 minhash:1.000 true SIM:0.667\n",
      "S2-S3 minhash:0.000 true SIM:0.000\n",
      "S2-S4 minhash:0.000 true SIM:0.333\n",
      "S3-S4 minhash:0.500 true SIM:0.200\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "my_matrix.index = range(my_matrix.shape[0])\n",
    "print('matrix:\\n{}\\n'.format(my_matrix))\n",
    "\n",
    "h_rows = [\n",
    "    [1, 2, 3, 4, 0],\n",
    "    [1, 4, 2, 0, 3]\n",
    "]\n",
    "\n",
    "def minhash_by_rows(matrix, row_orders):\n",
    "    \"\"\"calculate the minhash value of matrix according to row_permutation in Fig 3.4.\n",
    "    \n",
    "    \"\"\"\n",
    "    hash_fun_names = ['h{}'.format(i) for i in range(1, len(row_orders)+1)]\n",
    "    hash_table = pd.DataFrame(np.zeros((len(row_orders), matrix.shape[1])), index=hash_fun_names, columns=matrix.columns)\n",
    "\n",
    "    for row_order, hash_fun_name in zip(row_orders, hash_fun_names):\n",
    "        logging.debug('row_order:{}, h:{}'.format(row_order, hash_fun_name))\n",
    "        matrix_p = matrix.copy()\n",
    "        matrix_p.index = row_order #new rows permutation\n",
    "        matrix_p.sort_index(inplace=True) #adjust rows orders\n",
    "        \n",
    "        logging.debug('after permutation: \\n{}'.format(matrix_p))\n",
    "    \n",
    "        for c in matrix_p.columns:\n",
    "            first_one_index = next((i for i, x in enumerate(matrix_p.loc[:,c]) if x), None)\n",
    "            hash_table.loc[hash_fun_name, c] = first_one_index\n",
    "\n",
    "    return hash_table\n",
    "\n",
    "my_minhash_res = minhash_by_rows(my_matrix, h_rows)\n",
    "print('minhash: 5dim -> 2dim \\n\\\n",
    "       true hash res:\\n{}\\n'.format(my_minhash_res))\n",
    "\n",
    "print('Minhashing')\n",
    "\n",
    "for comb in list(itertools.combinations(range(4),2)):\n",
    "    s_a, s_b = 'S{}'.format(comb[0]+1), 'S{}'.format(comb[1]+1)\n",
    "    print('{}-{}'.format(s_a, s_b)),\n",
    "    \n",
    "    set_a, set_b = set(my_minhash_res.iloc[:,comb[0]]), set(my_minhash_res.iloc[:,comb[1]])\n",
    "    print('minhash:{:.3f}'.format(Jaccard_similarity_calc(set_a, set_b))),\n",
    "    print('true SIM:{:.3f}'.format(Jaccard_similarity_calc(set(my_features_dict[s_a]), set(my_features_dict[s_b]))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 $M$ 中的所有行做一次随机组合得到 $\\bar{M}$，非常耗时。    \n",
    "解决方法是不直接操作矩阵 $M$，而是分两步操作：\n",
    "\n",
    "1) 选择合适的哈希函数生成行号序列来模拟随机排列结果，如上个代码区块中 `h_rows` 即可用 $h_1(x) = (x + 1) \\% 5$ 和 $h_2(x) = (3x + 1) \\% 5$ 生成对应的行号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_rows:[[1, 2, 3, 4, 0], [1, 4, 2, 0, 3]]\n"
     ]
    }
   ],
   "source": [
    "def add_hash_func(a, b, c):\n",
    "    return lambda x: (a*x + b) % c\n",
    "\n",
    "h_funcs = [\n",
    "    add_hash_func(1, 1, 5),\n",
    "    add_hash_func(3, 1, 5)\n",
    "    ]\n",
    "\n",
    "h_rows = []\n",
    "for h_func in h_funcs:\n",
    "    h_rows.append(map(h_func, range(5)))\n",
    "    \n",
    "print('h_rows:{}'.format(h_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 再按照行号重新对行排序，生成新矩阵 $\\bar{M}$     \n",
    "但第 2 步排序仍然需要操作矩阵，见函数 `minhash_by_rows` 中的语句 `matrix_p.sort_index(inplace=True)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash functions computed for the matrix:\n",
      "   S1  S2  S3  S4  h1  h2\n",
      "0   1   0   0   1   1   1\n",
      "1   0   0   1   0   2   4\n",
      "2   0   1   0   1   3   2\n",
      "3   1   0   1   1   4   0\n",
      "4   0   0   1   0   0   3\n",
      "\n",
      "signature matrix\n",
      "(SIG):\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   0   1\n",
      "h2   0   2   0   0\n"
     ]
    }
   ],
   "source": [
    "#Fig 3.4\n",
    "\n",
    "df_matrix = my_matrix\n",
    "df_h_rows = pd.DataFrame(np.array(h_rows).T)\n",
    "df_h_rows.columns = ['h{}'.format(x+1) for x in df_h_rows.columns]\n",
    "\n",
    "print('Hash functions computed for the matrix:\\n{}\\n'.format(pd.concat([df_matrix, df_h_rows], axis=1)))\n",
    "print('signature matrix\\n(SIG):\\n{}'.format(my_minhash_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let SIG(i,c) be the element of the signature matrix for the ith hash function and column c.\n",
    "\n",
    "替代方法是借助思路：$ SIG(i,c) = min(h_i(S_c=1)) $    \n",
    "即对于 $h_i(S_c)$ 值来说，它只可能是 “1” 对应的行号，而第一个 “1” 肯定是最小的行号。\n",
    "\n",
    "比如，我们想得到 SIG(1,1) 的值，  \n",
    "$S1 = [1, 0, 0, 1, 0]^T$，对应的 $h1 = [1, 2, 3, 4, 0]^T$，    \n",
    "SIG(1,1) 只能取 “1” 的行号，即 1 或 4，    \n",
    "又 SIG 是第一个遇到的 “1”，所以 SIG(1,1) 肯定是 1。\n",
    "\n",
    "**思路总结**：    \n",
    "我们对每个 SIG(i,c) 都可以通过遍历 $S_i$ 中 \"1\" 位置，取出 $h_c$ 中相应位置的行号，行号中最小的值就是解。\n",
    "\n",
    "而这个思路是可以并行化处理的，有两种方法：\n",
    "\n",
    "1. 列遍历：即从左至右遍历 $S_i$ 得到 \"1\" 位置时，我们可以据此取出所有 $h_c$ 相应的行号，分别取最小。\n",
    "2. 行遍历：书中 Example3.8 例子，从上往下遍历，逐行比较。    \n",
    "   步骤如下：    \n",
    "   1. Compute $h_1(r), h_2(r), ... , h_n(r)$.\n",
    "   2. For each column $c$ do the following:\n",
    "       + If $c$ has $0$ in row $r$, do nothing\n",
    "       + else, if $c$ has $1$ in row $r$,   \n",
    "       for each $i = 1,2, ..., n$,     \n",
    "       $SIG(i,c) = min \\left( SIG(i,c), \\, h_i(r) \\right)$\n",
    "       \n",
    "行遍历的方法，粗略想，计算量应该更少。     \n",
    "`#todo: 验证计算量`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash matrix:\n",
      "   S1  S2  S3  S4  h1  h2\n",
      "0   1   0   0   1   1   1\n",
      "1   0   0   1   0   2   4\n",
      "2   0   1   0   1   3   2\n",
      "3   1   0   1   1   4   0\n",
      "4   0   0   1   0   0   3\n",
      "\n",
      "row:0,\n",
      " signature matrix:\n",
      "    S1   S2   S3  S4\n",
      "h1   1  inf  inf   1\n",
      "h2   1  inf  inf   1\n",
      "\n",
      "row:1,\n",
      " signature matrix:\n",
      "    S1   S2  S3  S4\n",
      "h1   1  inf   2   1\n",
      "h2   1  inf   4   1\n",
      "\n",
      "row:2,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   2   1\n",
      "h2   1   2   4   1\n",
      "\n",
      "row:3,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   2   1\n",
      "h2   0   2   0   0\n",
      "\n",
      "row:4,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   0   1\n",
      "h2   0   2   0   0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S1  S2  S3  S4\n",
       "h1   1   3   0   1\n",
       "h2   0   2   0   0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 3.8\n",
    "\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def minhash_signatures_calc(df_M, hash_funcs, nagging=False):\n",
    "    \"\"\"computing minhash signatures by the way in Example 3.8.\n",
    "    \n",
    "    \"\"\"\n",
    "    logging.debug('data matrix:\\n{}\\n'.format(df_M))\n",
    "\n",
    "    h = []\n",
    "    \n",
    "    for hash_func in hash_funcs:\n",
    "        h.append(map(hash_func, range(df_M.shape[0])))\n",
    "        \n",
    "    df_h = pd.DataFrame(np.array(h).T)\n",
    "    df_h.columns = ['h{}'.format(x+1) for x in df_h.columns]\n",
    "    logging.debug('hash matrix:\\n{}\\n'.format(df_h))\n",
    "    \n",
    "    if nagging:\n",
    "        print('hash matrix:\\n{}\\n'.format(pd.concat([df_matrix, df_h], axis=1)))\n",
    "    \n",
    "    df_signatures = pd.DataFrame(np.ones((df_h.shape[1], df_M.shape[1]))*np.inf, index=df_h.columns, columns=df_M.columns)\n",
    "    logging.debug('signatures matrix:\\ninit\\n{}\\n'.format(df_signatures))\n",
    "\n",
    "    for r in df_M.index:\n",
    "        for c in df_h.columns:\n",
    "            r_1_loc = df_M.loc[r,:] == 1\n",
    "            logging.debug('r:{}, c:{}, 1 loc:\\n{}\\n'.format(r,c, r_1_loc))\n",
    "            \n",
    "            sig_c = df_signatures.loc[c,:]\n",
    "            line_bigger_loc = sig_c > df_h.loc[r, c]\n",
    "            logging.debug('bigger row loc:\\n{}\\n'.format(line_bigger_loc))\n",
    "            \n",
    "            sig_c[line_bigger_loc & r_1_loc] = df_h.loc[r, c]\n",
    "            logging.debug('modified:\\n{}\\n'.format(sig_c))\n",
    "            \n",
    "            df_signatures.loc[c,:] = sig_c\n",
    "        if nagging:\n",
    "            print('row:{},\\n signature matrix:\\n{}\\n'.format(r, df_signatures))\n",
    "            \n",
    "    return df_signatures\n",
    "\n",
    "minhash_signatures_calc(df_matrix, h_funcs, nagging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### exercise 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1-S2 true SIM:0.000 fraction:0.000\n",
      "S1-S3 true SIM:0.250 fraction:0.250\n",
      "S1-S4 true SIM:0.667 fraction:0.667\n",
      "S2-S3 true SIM:0.000 fraction:0.000\n",
      "S2-S4 true SIM:0.333 fraction:0.333\n",
      "S3-S4 true SIM:0.200 fraction:0.200\n"
     ]
    }
   ],
   "source": [
    "#exercise 3.3.1\n",
    "\n",
    "#generate 120 permutations\n",
    "h_rows = list(itertools.permutations(range(5),5))\n",
    "my_minhash_res = minhash_by_rows(my_matrix, h_rows)\n",
    "\n",
    "for comb in list(itertools.combinations(range(4),2)):\n",
    "    s_a, s_b = 'S{}'.format(comb[0]+1), 'S{}'.format(comb[1]+1)\n",
    "    print('{}-{}'.format(s_a, s_b)),\n",
    "    #calc Jaccard similarity\n",
    "    print('true SIM:{:.3f}'.format(Jaccard_similarity_calc(set(my_features_dict[s_a]), set(my_features_dict[s_b])))),\n",
    "    #calc the fraction of the 120 permutations in which the value is same\n",
    "    print('fraction:{:.3f}'.format(sum(my_minhash_res.loc[:,s_a] == my_minhash_res.loc[:,s_b])/120))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash matrix:\n",
      "   S1  S2  S3  S4  h1  h2  h3  h4\n",
      "0   1   0   0   1   1   1   4   4\n",
      "1   0   0   1   0   2   4   1   2\n",
      "2   0   1   0   1   3   2   3   0\n",
      "3   1   0   1   1   4   0   0   3\n",
      "4   0   0   1   0   0   3   2   1\n",
      "\n",
      "row:0,\n",
      " signature matrix:\n",
      "    S1   S2   S3  S4\n",
      "h1   1  inf  inf   1\n",
      "h2   1  inf  inf   1\n",
      "h3   4  inf  inf   4\n",
      "h4   4  inf  inf   4\n",
      "\n",
      "row:1,\n",
      " signature matrix:\n",
      "    S1   S2  S3  S4\n",
      "h1   1  inf   2   1\n",
      "h2   1  inf   4   1\n",
      "h3   4  inf   1   4\n",
      "h4   4  inf   2   4\n",
      "\n",
      "row:2,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   2   1\n",
      "h2   1   2   4   1\n",
      "h3   4   3   1   3\n",
      "h4   4   0   2   0\n",
      "\n",
      "row:3,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   2   1\n",
      "h2   0   2   0   0\n",
      "h3   0   3   0   0\n",
      "h4   3   0   2   0\n",
      "\n",
      "row:4,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   1   3   0   1\n",
      "h2   0   2   0   0\n",
      "h3   0   3   0   0\n",
      "h4   3   0   1   0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S1  S2  S3  S4\n",
       "h1   1   3   0   1\n",
       "h2   0   2   0   0\n",
       "h3   0   3   0   0\n",
       "h4   3   0   1   0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exercise 3.3.2\n",
    "h_funcs[2:4] = [\n",
    "    add_hash_func(2, 4, 5),\n",
    "    add_hash_func(3, -1, 5)\n",
    "]\n",
    "\n",
    "minhash_signatures_calc(df_matrix, h_funcs, nagging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fig 3.5:\n",
      "   S1  S2  S3  S4\n",
      "0   0   1   0   1\n",
      "1   0   1   0   0\n",
      "2   1   0   0   1\n",
      "3   0   0   1   0\n",
      "4   0   0   1   1\n",
      "5   1   0   0   0\n",
      "\n",
      "hash matrix:\n",
      "   S1  S2  S3  S4  h1  h2  h3\n",
      "0   0   1   0   1   1   2   2\n",
      "1   0   1   0   0   3   5   1\n",
      "2   1   0   0   1   5   2   0\n",
      "3   0   0   1   0   1   5   5\n",
      "4   0   0   1   1   3   2   4\n",
      "5   1   0   0   0   5   5   3\n",
      "\n",
      "row:0,\n",
      " signature matrix:\n",
      "     S1  S2   S3  S4\n",
      "h1  inf   1  inf   1\n",
      "h2  inf   2  inf   2\n",
      "h3  inf   2  inf   2\n",
      "\n",
      "row:1,\n",
      " signature matrix:\n",
      "     S1  S2   S3  S4\n",
      "h1  inf   1  inf   1\n",
      "h2  inf   2  inf   2\n",
      "h3  inf   1  inf   2\n",
      "\n",
      "row:2,\n",
      " signature matrix:\n",
      "    S1  S2   S3  S4\n",
      "h1   5   1  inf   1\n",
      "h2   2   2  inf   2\n",
      "h3   0   1  inf   0\n",
      "\n",
      "row:3,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   5   1   1   1\n",
      "h2   2   2   5   2\n",
      "h3   0   1   5   0\n",
      "\n",
      "row:4,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   5   1   1   1\n",
      "h2   2   2   2   2\n",
      "h3   0   1   4   0\n",
      "\n",
      "row:5,\n",
      " signature matrix:\n",
      "    S1  S2  S3  S4\n",
      "h1   5   1   1   1\n",
      "h2   2   2   2   2\n",
      "h3   0   1   4   0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S1  S2  S3  S4\n",
       "h1   5   1   1   1\n",
       "h2   2   2   2   2\n",
       "h3   0   1   4   0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exercise 3.3.3\n",
    "\n",
    "my_database = range(6)\n",
    "my_features_dict = {\n",
    "    'S1':[2, 5],\n",
    "    'S2':[0, 1],\n",
    "    'S3':[3, 4],\n",
    "    'S4':[0, 2, 4]\n",
    "    }\n",
    "\n",
    "df_fig_3_5 = matrix_representation_create(my_database, my_features_dict)\n",
    "print('Fig 3.5:\\n{}\\n'.format(df_fig_3_5))\n",
    "\n",
    "\n",
    "#(a)\n",
    "h_funcs = [\n",
    "    add_hash_func(2, 1, 6),\n",
    "    add_hash_func(3, 2, 6),\n",
    "    add_hash_func(5, 2, 6)\n",
    "]\n",
    "df_matrix = df_fig_3_5\n",
    "my_minhash_res = minhash_signatures_calc(df_matrix, h_funcs, nagging=True)\n",
    "my_minhash_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1-S2 minhash:0.250 true SIM:0.000\n",
      "S1-S3 minhash:0.200 true SIM:0.000\n",
      "S1-S4 minhash:0.500 true SIM:0.250\n",
      "S2-S3 minhash:0.667 true SIM:0.000\n",
      "S2-S4 minhash:0.667 true SIM:0.250\n",
      "S3-S4 minhash:0.500 true SIM:0.250\n"
     ]
    }
   ],
   "source": [
    "#(b) h_3 is a true permutation.\n",
    "\n",
    "#(c)\n",
    "\n",
    "for comb in list(itertools.combinations(range(4),2)):\n",
    "    s_a, s_b = 'S{}'.format(comb[0]+1), 'S{}'.format(comb[1]+1)\n",
    "    print('{}-{}'.format(s_a, s_b)),\n",
    "    \n",
    "    set_a, set_b = set(my_minhash_res.iloc[:,comb[0]]), set(my_minhash_res.iloc[:,comb[1]])\n",
    "    print('minhash:{:.3f}'.format(Jaccard_similarity_calc(set_a, set_b))),\n",
    "    print('true SIM:{:.3f}'.format(Jaccard_similarity_calc(set(my_features_dict[s_a]), set(my_features_dict[s_b]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#exercise 3.3.4`   \n",
    "不是很明白意思，大概想法是：    \n",
    "从 $n$ 中抽取 $m$ 个元素集合 $S$ 和 $T$，则从 $S$ 和 $T$ 中各抽一次，元素相同的概率是多少？\n",
    "\n",
    "`#exercise 3.3.5`   \n",
    "元素相同的概率是 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Locality-Sensitive Hashing for Documents\n",
    "\n",
    "minhash 降低了维度，但计算耗时问题仍然存在：  \n",
    "令样本集有 $k$ 个元素，两两比较次数是 $C_k^2 = O(k^2)$。    \n",
    "若 $k$ 很大，则比较次数成乘方倍增长。\n",
    "\n",
    "解决思路：   \n",
    "1. 并行处理    \n",
    "2. 只比较可能相似的样本    \n",
    "   often we want only the most similar pairs or all paris that are above some lower bound in similarity.     \n",
    "   ----> Locality-sensitive hasing (LSH) or near-neighbor search.\n",
    "   \n",
    "**LSH**:   \n",
    "\"hash\" items several times, in such a way: $$P[\\text{similar items in the same bucket}] >> P[\\text{dissimilar ...}]$$\n",
    "\n",
    "candidate pair: any pair hashed to the same bucket.   \n",
    "false postive: dissimilar items in the candidate pair.    \n",
    "false negtive: similar items NOT in the cnadidate pair.\n",
    "\n",
    "if we have minhash signatures for the items, an effective way to choose the hashings is:    \n",
    "1. divide the signature matrix into $b$ bands consisting of $r$ rows each.\n",
    "2. for each band $b_i$, hash each vector in $b_i$   \n",
    "   hash function $h$: same vectors -> same bucket\n",
    "   \n",
    "也就是说，将两个样本向量分割，只要有一个节点哈希到一起，就认为是候选对。\n",
    "\n",
    "注意，统计的是每个节点各自哈希的情况，所以每个节点使用相同的哈希函数，但使用独立的哈希表存储中间结果。如下图：\n",
    "\n",
    "matrix | --> | hash table\n",
    ":-------:|:------:|:------------:\n",
    "band 1 | h(v) | hash_talbe_1\n",
    "band 2 | h(v) | hash_talbe_2\n",
    "....   | h(v) | ....\n",
    "\n",
    "\n",
    "**Analysis** the probabilty of two pairs to become a candidate pairs:   \n",
    "Given the pairs $s_a$ and $s_b$ have Jaccard similarity $s$, we use $b$ bands of $r$ row each to split their signature matrix $M_a$ and $M_b$.    \n",
    "1. $\\forall \\, i^{th} \\, \\text{row}, \\, prob_{rowY} = P[M_a[i,:] == M_b[i,:]] = \\text{Jaccard similarity} = s$\n",
    "2. the possibility that one band($r$ row) is the same is: $$prob_{bandY} = prob_{rowY}^r = s^r$$\n",
    "   .......................................not the same is: $$prob_{bandN} = 1 - prob_{bandY} = 1 - s^r$$\n",
    "3. $s_a$ and $s_b$ are totally different: $$prob_{pairN} = prob_{bandN}^b = (1 - s^r)^b$$\n",
    "   $s_a$ and $_b$ **at least agree in one band**: $$prob_{pairY} = 1 - prob_{pairN} = 1 - (1 - s^r)^b$$\n",
    "   \n",
    "\n",
    "**threshold**: the value of $s$ at which the probability of becoming a candidate is 1/2.    \n",
    "namely, $1 - (1 - s^r)^b = \\frac{1}{2}$, the solution $s \\approx (1/b)^{1/r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.20000000000000001, 0.0063805813047682625),\n",
       " (0.30000000000000004, 0.047494259124971183),\n",
       " (0.40000000000000008, 0.18604955214914409),\n",
       " (0.50000000000000011, 0.47005071531687648),\n",
       " (0.60000000000000009, 0.80190245383822212),\n",
       " (0.70000000000000018, 0.97478054418804061),\n",
       " (0.80000000000000027, 0.99964394210947927)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10907ab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example 3.11\n",
    "\n",
    "b = 20\n",
    "r = 5\n",
    "s = np.linspace(0, 1, 100)\n",
    "\n",
    "def p(s, r, b):\n",
    "    return 1 - (1 - s**r)**b\n",
    "\n",
    "plot(s,p(s, r, b))\n",
    "\n",
    "s = np.arange(0.2, 0.9, 0.1)\n",
    "\n",
    "zip(s, p(s, r, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we consider two documents with 80% similarity, then their false negative is $1 - 0.99964... \\approx 0.00035$, which means that only roughly 1 in 3000 pairs that are as high as 80% similar will fail to become a candidate pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining the Techniques\n",
    "整合前面讲过的方法，找到相似文本的方法如下：\n",
    "\n",
    "1. k-shingles    \n",
    "   [opt] hash k-shignles to shorter bucket numbers   \n",
    "\n",
    "2. Sort the document-shigles pairs    \n",
    "   不用生成完成的矩阵，而是依据 shingles 顺序后面用到时逐行生成（节省内存）\n",
    "   \n",
    "3. Pick n, compute the minhash signatures by feed the sorted list line by line     \n",
    "   逐行遍历\n",
    "   \n",
    "4. Choose a threshold $t$    \n",
    "   $t \\approx (1/b)^{1/r}$ and $n = b \\times n$ to determine appropriate $b, n$.\n",
    "   \n",
    "5. Construct candidate pairs using LSH\n",
    "\n",
    "6. Examine each candidate pair's signatures, $SIM > t$?\n",
    "\n",
    "7. [opt] check document themselve\n",
    "\n",
    "`#todo: 找个例子，代码实现`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### exercise 3.4\n",
    "`#maybe:`\n",
    "\n",
    "`#exercise 3.4.3`\n",
    "\n",
    "`#exercise 3.4.4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Distance Measures\n",
    "\n",
    "**LSH** 本身的意义：   \n",
    "就是为一个特定的距离 $l$，找到合适的哈希函数 $h$ 来实现 \"S\" 曲线的效果：   \n",
    "即此距离下越近，哈希到同一区块的可能性越高。\n",
    "\n",
    "这章介绍距离，为下一章找哈希函数打基础。   \n",
    "\n",
    "##### 距离的定义\n",
    "\n",
    "定义集合 $X$ 上的度量為一函數距离 $d: X \\times X \\to \\mathbf{R}$    \n",
    "对于 $\\forall x, y, z \\in X$，应满足：\n",
    "\n",
    "1. 正定性    \n",
    "$d(x, y) \\ge 0$    \n",
    "$d(x, y) = 0$ if and only if $x = y$\n",
    "\n",
    "2. 交换性    \n",
    "$d(x, y) = d(y, x)$\n",
    "\n",
    "3. 三角不等式    \n",
    "$d(x, y) \\le d(x, z) + d(z, y)$\n",
    "\n",
    "\n",
    "##### 几种距离\n",
    "1. Euclidean Distance: $\\| \\cdot \\|_2$    \n",
    "   $L_r\\text{-norm} = (\\sum \\| \\cdot \\|_1^r)^{1/r}$    \n",
    "   $L_\\infty\\text{-norm} = max(\\| \\cdot \\|_1)$\n",
    "   \n",
    "2. Jaccard Distance: $d(x, y) = 1 - SIM(x, y)$\n",
    "\n",
    "3. Cosine Distance: $d(x, y) = \\frac{x \\cdot y}{\\|x\\|_2 + \\|y\\|_2}$\n",
    "\n",
    "4. Edit Distance:      \n",
    "   Given $x = x_1 x_2 ...$, $y = y_1 y_2 ...$.   \n",
    "   $d(x, y)$ is the smallest number of insertion and deletion of single char($x \\to y$).\n",
    "\n",
    "   $d(x, y) = len(x) + len(y) - 2 LCS(x, y)$    \n",
    "   LCS is the longest common subsequence of $x$ and $y$.\n",
    "\n",
    "5. Hamming Distance: $d(x, y) = sum( \\, diff(x, y) \\,)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.6 The Theory of Locality-Sensitive Function\n",
    "\n",
    "对于每种距离定义，需要找到合适的哈希函数使其满足 $P-S$ 是 \"S\" 型曲线（越相似，概率越高）。\n",
    "\n",
    "a family of functions should statify 3 conditions:\n",
    "\n",
    "1. $P[\\text{close pairs become candidate pairs}] > P[\\text{dissimilar pairs...}]$\n",
    "\n",
    "2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
