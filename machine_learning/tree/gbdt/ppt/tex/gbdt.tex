% -*- coding: utf-8 -*-

\section{Gradient Boost Decision Tree (GBDT)}
% http://nbviewer.jupyter.org/github/facaiy/book_notes/blob/master/machine_learning/tree/gbdt/intro.ipynb
% http://nbviewer.jupyter.org/github/facaiy/book_notes/blob/master/machine_learning/tree/gbdt/spark/intro.ipynb
\subsection{直观印象}
% 模型叠加
% 残差

\subsection{算法流程}
% https://en.wikipedia.org/wiki/Gradient_boosting
%% greedy: pdf, Algorithm 1

\subsection{从最优化角度的理解}
% 从最速下降法来理解
%% L(,) 距离函数
%% 一维 U
%% 二维 曲面

\subsection{从泛函角度的理解}
% 泛函，不是数据在变，而是函数在变
%% 训练是找到函数
%% 预测是找到输出

% 为什么选择决策树？
% 数据，泰勒展开， 正交基底
%% 加法模型 = 正交基底，函数空间

\subsection{从降维角度的理解}
% PCA
%% 数据特征的降维 -> 函数空间的降维
%% 矩阵分解

% 寻优耗时
% spark,实现，没有寻优 => tree boost
