{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../../preconfig.py\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "#sns.set(font='SimHei')\n",
    "#plt.rcParams['axes.grid'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "#import sklearn\n",
    "\n",
    "#import itertools\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树简介和 Python 实现\n",
    "======================\n",
    "参考：\n",
    "\n",
    "+ [Building a decision tree from scratch - a beginner tutorial](http://www.patricklamle.com/Tutorials/Decision%20tree%20python/tuto_decision%20tree.html)\n",
    "\n",
    "+ 9.2 Tree-Based Methods - The Elements of Statistical Learning\n",
    "\n",
    "+ [Classification and Regression Trees (CART) Theory and Applications](http://edoc.hu-berlin.de/master/timofeev-roman-2004-12-20/PDF/timofeev.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 基本介绍\n",
    "本文主要是参照 Tree-Based Methods - The Elements of Statistical Learning 来实现一个简化版范例，其算法是 CART。\n",
    "\n",
    "决策树的思想本身非常朴素，关于它的基本介绍在网上已经非常丰富，比如：\n",
    "\n",
    "+ [算法杂货铺——分类算法之决策树(Decision tree)](http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html)\n",
    "\n",
    "其主要问题是在每次决策时找到一个分割点，让生成的子集尽可能地纯净。这里涉及到四个问题:\n",
    "\n",
    "1. 如何分割样本？\n",
    "\n",
    "2. 如何评价子集的纯净度？\n",
    "\n",
    "3. 如何找到单个最佳的分割点，其子集最为纯净？\n",
    "\n",
    "4. 如何找到最佳的分割点序列，其最终分割子集总体最为纯净？\n",
    "\n",
    "接下来，围绕上述问题，一一概要说明，并加以演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据\n",
    "\n",
    "古话说，「三军未动，粮草先行」。\n",
    "\n",
    "我们先加载演示数据，使用的是 sklearn 自带的测试用例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备特征数据\n",
    "X = pd.DataFrame(data.data, \n",
    "                 columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0  setosa\n",
       "1  setosa\n",
       "2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备标签数据\n",
    "y = pd.DataFrame(data.target, columns=['target'])\n",
    "y.replace(to_replace=range(3), value=data.target_names, inplace=True)\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 组建样本 [特征，标签]\n",
    "samples = pd.concat([X, y], axis=1) #, keys=[\"x\", \"y\"])\n",
    "samples.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 如何分割样本\n",
    "决策树的分割方法是取一个特征 $f$ 和阈值 $t$，以此为界将样本 $X$ 拆分为两个子集 $X_l, X_r$。其数学表达形同：\n",
    "\n",
    "\\begin{align}\n",
    "    X = \\begin{cases}\n",
    "        X_l, \\ \\text{if } X[f] < t \\\\\n",
    "        X_r, \\ \\text{if } X[f] \\geq t\n",
    "    \\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitter(samples, feature, threshold):\n",
    "    # 按特征 f 和阈值 t 分割样本\n",
    "    \n",
    "    left_nodes = samples.query(\"{f} < {t}\".format(f=feature, t=threshold))\n",
    "    right_nodes = samples.query(\"{f} >= {t}\".format(f=feature, t=threshold))\n",
    "    \n",
    "    return {\"left_nodes\": left_nodes, \"right_nodes\": right_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        20\n",
       "versicolor     1\n",
       "virginica      1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = splitter(samples, \"sepal_length\", 5)\n",
    "\n",
    "# 左子集\n",
    "x_l = split[\"left_nodes\"].loc[:, \"target\"].value_counts()\n",
    "x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     49\n",
       "versicolor    49\n",
       "setosa        30\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 右子集\n",
    "x_r = split[\"right_nodes\"].loc[:, \"target\"].value_counts()\n",
    "x_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 如何评价子集的纯净度？\n",
    "\n",
    "从常理来说，我们希望分割子集尽可能地纯净，最好是单个子集就只含有一类标签，从而保证决策结果精准。\n",
    "\n",
    "那么什么样的评价函数，可以用来度量各子集的纯净度呢？\n",
    "\n",
    "以刚才计算结果为例， $x_l$ 主要标签是 setosa，非常纯净，而 $x_r$ 则三种标签势均力敌，非常混杂。所以思路是，若一种标签在子集中占比非常大，则此子集就较纯净；若各标签占比差别不大，就较为混杂。\n",
    "\n",
    "常用的评价函数正是计算各标签 $c_k$ 在子集中的占比 $p_k = c_k / \\sum (c_k)$，并通过组合 $p_k$ 来描述占比集中或分散。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_class_proportion(node):\n",
    "    # 计算各标签在集合中的占比\n",
    "    \n",
    "    y = node[\"target\"]\n",
    "    return y.value_counts() / y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        0.909091\n",
       "versicolor    0.045455\n",
       "virginica     0.045455\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_class_proportion(split[\"left_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     0.382812\n",
       "versicolor    0.382812\n",
       "setosa        0.234375\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_class_proportion(split[\"right_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要的评价函数有三种，它们评价的是集合的不纯度（值越大，集合越混杂）。\n",
    "\n",
    "先做些数学定义以便于描述：     \n",
    "假设对于集合 $m$ 有 $N_m$ 个样本，可分割成 $R_m$ 子集。     \n",
    "若总的标签类别有 $K$ 种，则标签 $k$ 在此集合中的占比为：\n",
    "\\begin{equation}\n",
    "    \\hat{p}_{m k} = \\frac{1}{N_m} \\displaystyle \\sum_{x_i \\in R_m} I(y_i = k)\n",
    "\\end{equation}\n",
    "\n",
    "且令标签 $k$ 是占比最大的标签，即 $k(m) = \\operatorname{arg max}_k \\hat{p}_{m k}$.\n",
    "\n",
    "##### 1. Misclassification error\n",
    "我们一般把集合的分类结果定义为占比最大的标签，那么落在此集合中的其它标签就是误分类。其比率是 $1 - \\hat{p}_{m k}(m)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misclassification_error(node):\n",
    "    p_mk = calc_class_proportion(node)\n",
    "    \n",
    "    return 1 - p_mk.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090909090909090939"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_error(split[\"left_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_error(split[\"right_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，误分类率和占比 $p$ 的关系可划图为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_p = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini_index(node):\n",
    "    p_mk = calc_class_proportion(node)\n",
    "    \n",
    "    return (p_mk * (1 - p_mk)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1694214876033058"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_index(split[\"left_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6519775390625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_index(split[\"right_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_entropy(node):\n",
    "    p_mk = calc_class_proportion(node)\n",
    "    \n",
    "    return - (p_mk * p_mk.apply(np.log)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36764947740014225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(split[\"left_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.075199711851601"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(split[\"right_nodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 最优分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_impurity_measure(node, feathure, threshold, measure, min_nodes=5):\n",
    "    child = splitter(node, feathure, threshold)\n",
    "    left = child[\"left_nodes\"]\n",
    "    right = child[\"right_nodes\"]\n",
    "    \n",
    "    if left.shape[0] <= min_nodes or right.shape[0] <= min_nodes:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    impurity = pd.DataFrame([], \n",
    "                       columns=[\"score\", \"rate\"],\n",
    "                       index=[])\n",
    "    \n",
    "    impurity.loc[\"all\"] = [measure(node), node.shape[0]]\n",
    "    impurity.loc[\"left\"] = [-measure(left), left.shape[0]]\n",
    "    impurity.loc[\"right\"] = [-measure(right), right.shape[0]]\n",
    "    \n",
    "    impurity[\"rate\"] /= impurity.at[\"all\", \"rate\"]\n",
    "    \n",
    "    logger.info(impurity)\n",
    "    \n",
    "    return (impurity[\"score\"] * impurity[\"rate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08546401515151514"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_impurity_measure(samples, \"sepal_length\", 5, gini_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_threshold(node, feature, measure):\n",
    "    threshold_candidates = node[feature].quantile(np.arange(0, 1, 0.2))\n",
    "    \n",
    "    res = pd.Series([], name=feature)\n",
    "    for t in threshold_candidates:\n",
    "        res[t] = calc_impurity_measure(node, feature, t, measure)\n",
    "    \n",
    "    logger.info(res)\n",
    "    \n",
    "    if res.max() == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return res.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3999999999999999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_threshold(samples, \"sepal_width\", gini_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5999999999999996"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_threshold(samples, \"sepal_length\", gini_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(node, measure):\n",
    "    if node[\"target\"].unique().shape[0] <= 1:\n",
    "        return None\n",
    "    \n",
    "    purity_gain = pd.Series([], name=\"feature\")\n",
    "    \n",
    "    for f in node.drop(\"target\", axis=1).columns:\n",
    "        purity_gain[f] = find_best_threshold(node, f, measure)\n",
    "        \n",
    "    if pd.isnull(purity_gain.max()):\n",
    "        return None\n",
    "    else:\n",
    "        best_split = {\"feature\": purity_gain.argmax(), \"threshold\": purity_gain.max()}\n",
    "        best_split[\"child\"] = splitter(node, **best_split)\n",
    "\n",
    "        return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'child': {'left_nodes':      sepal_length  sepal_width  petal_length  petal_width      target\n",
       "  0             5.1          3.5           1.4          0.2      setosa\n",
       "  1             4.9          3.0           1.4          0.2      setosa\n",
       "  2             4.7          3.2           1.3          0.2      setosa\n",
       "  3             4.6          3.1           1.5          0.2      setosa\n",
       "  4             5.0          3.6           1.4          0.2      setosa\n",
       "  5             5.4          3.9           1.7          0.4      setosa\n",
       "  6             4.6          3.4           1.4          0.3      setosa\n",
       "  7             5.0          3.4           1.5          0.2      setosa\n",
       "  8             4.4          2.9           1.4          0.2      setosa\n",
       "  9             4.9          3.1           1.5          0.1      setosa\n",
       "  ..            ...          ...           ...          ...         ...\n",
       "  59            5.2          2.7           3.9          1.4  versicolor\n",
       "  60            5.0          2.0           3.5          1.0  versicolor\n",
       "  80            5.5          2.4           3.8          1.1  versicolor\n",
       "  81            5.5          2.4           3.7          1.0  versicolor\n",
       "  84            5.4          3.0           4.5          1.5  versicolor\n",
       "  89            5.5          2.5           4.0          1.3  versicolor\n",
       "  90            5.5          2.6           4.4          1.2  versicolor\n",
       "  93            5.0          2.3           3.3          1.0  versicolor\n",
       "  98            5.1          2.5           3.0          1.1  versicolor\n",
       "  106           4.9          2.5           4.5          1.7   virginica\n",
       "  \n",
       "  [59 rows x 5 columns],\n",
       "  'right_nodes':      sepal_length  sepal_width  petal_length  petal_width      target\n",
       "  14            5.8          4.0           1.2          0.2      setosa\n",
       "  15            5.7          4.4           1.5          0.4      setosa\n",
       "  18            5.7          3.8           1.7          0.3      setosa\n",
       "  50            7.0          3.2           4.7          1.4  versicolor\n",
       "  51            6.4          3.2           4.5          1.5  versicolor\n",
       "  52            6.9          3.1           4.9          1.5  versicolor\n",
       "  54            6.5          2.8           4.6          1.5  versicolor\n",
       "  55            5.7          2.8           4.5          1.3  versicolor\n",
       "  56            6.3          3.3           4.7          1.6  versicolor\n",
       "  58            6.6          2.9           4.6          1.3  versicolor\n",
       "  ..            ...          ...           ...          ...         ...\n",
       "  140           6.7          3.1           5.6          2.4   virginica\n",
       "  141           6.9          3.1           5.1          2.3   virginica\n",
       "  142           5.8          2.7           5.1          1.9   virginica\n",
       "  143           6.8          3.2           5.9          2.3   virginica\n",
       "  144           6.7          3.3           5.7          2.5   virginica\n",
       "  145           6.7          3.0           5.2          2.3   virginica\n",
       "  146           6.3          2.5           5.0          1.9   virginica\n",
       "  147           6.5          3.0           5.2          2.0   virginica\n",
       "  148           6.2          3.4           5.4          2.3   virginica\n",
       "  149           5.9          3.0           5.1          1.8   virginica\n",
       "  \n",
       "  [91 rows x 5 columns]},\n",
       " 'feature': 'sepal_length',\n",
       " 'threshold': 5.5999999999999996}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(samples, gini_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 递归查最优分割点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinaryNode:\n",
    "    def __init__(self, samples, max_depth, measure=gini_index):\n",
    "        self.samples = samples\n",
    "        self.max_depth = max_depth\n",
    "        self.measure = measure\n",
    "        \n",
    "        self.is_leaf = False\n",
    "        self.class_ = None\n",
    "        \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        self.best_split = None\n",
    "    \n",
    "    def split(self, depth):\n",
    "        if depth > self.max_depth:\n",
    "            self.is_leaf = True\n",
    "            self.class_ = self.samples[\"target\"].value_counts().argmax()\n",
    "            return\n",
    "        \n",
    "        best_split = find_best_split(self.samples, self.measure)\n",
    "        if pd.isnull(best_split):\n",
    "            self.is_leaf = True\n",
    "            self.class_ = self.samples[\"target\"].value_counts().argmax()\n",
    "            return\n",
    "\n",
    "        self.best_split = best_split\n",
    "        left = self.best_split[\"child\"][\"left_nodes\"]\n",
    "        self.left = BinaryNode(left.drop(best_split[\"feature\"], axis=1), self.max_depth)\n",
    "        \n",
    "        right = self.best_split[\"child\"][\"right_nodes\"]\n",
    "        self.right = BinaryNode(right.drop(best_split[\"feature\"], axis=1), self.max_depth)\n",
    "\n",
    "        self.left.split(depth+1)\n",
    "        self.right.split(depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binaryNode = BinaryNode(samples, 3)\n",
    "binaryNode.split(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(node, depth):\n",
    "    if node.left:\n",
    "        show(node.left, depth+1)\n",
    "    \n",
    "    if node.is_leaf:\n",
    "        print(\"{}{}\".format(\"\\t\"*(depth+2), node.class_))\n",
    "        return \n",
    "    else:\n",
    "        print(\"{}{}: {}\".format(\"\\t\"*depth,\n",
    "                                node.best_split[\"feature\"],\n",
    "                                node.best_split[\"threshold\"]))\n",
    "    if node.right:\n",
    "        show(node.right, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tversicolor\n",
      "\tsepal_width: 2.8200000000000003\n",
      "\t\t\t\t\tsetosa\n",
      "\t\tpetal_length: 1.6\n",
      "\t\t\t\t\t\tsetosa\n",
      "\t\t\tpetal_width: 0.4\n",
      "\t\t\t\t\t\tsetosa\n",
      "sepal_length: 5.6\n",
      "\t\t\t\t\tversicolor\n",
      "\t\tsepal_width: 3.1\n",
      "\t\t\t\t\tversicolor\n",
      "\tpetal_length: 4.8\n",
      "\t\t\t\t\t\tversicolor\n",
      "\t\t\tpetal_width: 1.8\n",
      "\t\t\t\t\t\tvirginica\n",
      "\t\tsepal_width: 2.9\n",
      "\t\t\t\t\t\tvirginica\n",
      "\t\t\tpetal_width: 2.0\n",
      "\t\t\t\t\t\tvirginica\n"
     ]
    }
   ],
   "source": [
    "show(binaryNode, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
