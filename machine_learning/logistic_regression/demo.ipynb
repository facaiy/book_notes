{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /Users/facai/Study/book_notes/preconfig.py\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归算法简介和Python实现\n",
    "========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 实验数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x                                   y\n",
       "   0    1   2   3  4     5      6   7  8\n",
       "0  6  148  72  35  0  33.6  0.627  50  1\n",
       "1  1   85  66  29  0  26.6  0.351  31  0\n",
       "2  8  183  64   0  0  23.3  0.672  32  1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [(\"x\", k) for k in range(8)] + [(\"y\", 8)]\n",
    "df = pd.read_csv(\"./res/dataset/pima-indians-diabetes.data\", names=names)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 二分类\n",
    "\n",
    "#### 1.0 基本原理\n",
    "\n",
    "ref: http://www.robots.ox.ac.uk/~az/lectures/ml/2011/lect4.pdf\n",
    "\n",
    "逻辑回归，是对线性分类 $f(x) = w^T x + b$ 结果，额外做了sigmoid变换$\\sigma(x) = \\frac1{1 + e^x}$。加了sigmoid变换，更适合于做分类器，效果见下图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1146cca20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD3CAYAAAD/oDhxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3sfGWLa/NwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146cc208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-1.5, 1.5, 1000)\n",
    "\n",
    "y1 = 0.5 * x + 0.5\n",
    "y2 = sp.special.expit(5 * x)\n",
    "\n",
    "pd.DataFrame({'linear': y1, 'logistic regression': y2}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，逻辑回归的定义式是\n",
    "\n",
    "\\begin{equation}\n",
    "  g(x) = \\sigma(f(x)) = \\frac1{1 + e^{-(w^T x + b)}}\n",
    "\\end{equation}\n",
    "\n",
    "那么问题来了，如何找到参数$w$呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.0.0 损失函数\n",
    "\n",
    "在回答如何找之前，我们得先定义找什么：即什么参数是好的？\n",
    "\n",
    "观察到，对于二分类 $y \\in \\{-1, 1\\}$，有\n",
    "\n",
    "\\begin{align}\n",
    "  g(x) & \\to 1 \\implies y = 1 \\\\\n",
    "  1 - g(x) & \\to 1 \\implies y = 0\n",
    "\\end{align}\n",
    "\n",
    "可以将$g(x)$看作是$y = 1$的概率值，$1 - g(x)$看作是$y = 0$的概率值，整理为：\n",
    "\n",
    "\\begin{align}\n",
    "  P(y = 1 | x, w) &= g(x) & &= \\frac1{1 + e^{-z}} &= \\frac1{1 + e^{-y z}} \\\\\n",
    "  P(y = 0 | x, w) &= 1 - g(x) &= 1 - \\frac1{1 + e^{-z}} &= \\frac1{1 + e^z} &= \\frac1{1 + e^{-y z}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "即，可合并为 $P(y|x, w) = \\frac1{1 + e^{-y z}}$，其中$z = w^T x + b$。\n",
    "\n",
    "好了，常理而言，我们可以认为，对于给定的$x$，有$w$，使其对应标签$y$的概率值越大，则此$w$参数越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练数据中是有许多样本的，即有多个$x$，如何全部利用起来呢？\n",
    "\n",
    "假定样本间是独立的，最直接的想法是将它们的预测概率值累乘，又称[Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)\n",
    "\n",
    "\\begin{equation}\n",
    "{\\mathcal {L}}(\\theta \\,;\\,x_{1},\\ldots ,x_{n})=f(x_{1},x_{2},\\ldots ,x_{n}\\mid \\theta )=\\prod _{i=1}^{n}f(x_{i}\\mid \\theta )\n",
    "\\end{equation}\n",
    "\n",
    "好，我们用这个方法来描述最合适的参数$w$是\n",
    "\n",
    "\\begin{align}\n",
    "  w &= \\operatorname{arg \\ max} \\prod_i^n P(y_i | x_i, w) \\\\\n",
    "    &= \\operatorname{arg \\ min} - \\log \\left ( \\prod_i^n P(y_i | x_i, w) \\right ) \\quad \\text{用negative log likelihood转成极小值} \\\\\n",
    "    & = \\operatorname{arg \\ min} - \\log \\left ( \\prod_i^n \\frac1{1 + e^{-y z}} \\right ) \\\\\n",
    "    & = \\operatorname{arg \\ min} \\sum_i^n - \\log \\left ( \\frac1{1 + e^{-y z}} \\right ) \\\\\n",
    "    & = \\operatorname{arg \\ min} \\sum_i^n \\log ( 1 + e^{-y z} ) \\\\\n",
    "\\end{align}\n",
    "\n",
    "于是，我们可以定义损失函数\n",
    "\n",
    "\\begin{equation}\n",
    "  L(w) = \\log (1 + e^{-y z}) = \\log \\left ( 1 + e^{-y (w^T x + b)} \\right )\n",
    "\\end{equation}\n",
    "\n",
    "最好旳$w$值是$\\operatorname{arg \\ min} L(w)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.0.1 一阶导数\n",
    "\n",
    "知道找什么这个目标后，怎么找就比较套路了。因为定义了损失函数，很自然地可以用数值寻优方法来寻找。很多数值寻优方法需要用到一阶导数信息，所以简单对损失函数求导，可得:\n",
    "\n",
    "\\begin{align}\n",
    "  \\frac{\\partial L}{\\partial w} &= \\frac1{1 + e^{-y (w^T x + b)}} \\cdot e^{-yb} \\cdot -yx e^{-y w^T x} \\\\\n",
    "    &= \\frac{e^{-y (w^T x + b)}}{1 + e^{-y (w^T x + b)}} \\cdot -y x \\\\\n",
    "    &= -y \\left ( 1 - \\frac1{1 + e^{-y (w^T x + b)}} \\right ) x\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "有了损失函数和导数，用数值寻优方法就可找到合适的$w$值，具体见下一节的演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 实现演示\n",
    "\n",
    "上一节，我们得到了损失函数和导数：\n",
    "\n",
    "\\begin{align}\n",
    "  L(w) &= \\log \\left ( 1 + e^{-y (w^T x + b)} \\right ) \\\\\n",
    "  \\frac{\\partial L}{\\partial w}  &= -y \\left ( 1 - \\frac1{1 + e^{-y (w^T x + b)}} \\right ) x\n",
    "\\end{align}\n",
    "\n",
    "对于$n$个训练样本，需要加总起来：\n",
    "\n",
    "\\begin{align}\n",
    "  L(w) &= \\sum_i^n \\log \\left ( 1 + e^{-y (w^T x + b)} \\right ) \\\\\n",
    "  \\frac{\\partial L}{\\partial w} &= \\sum_i^n -y \\left ( 1 - \\frac1{1 + e^{-y (w^T x + b)}} \\right ) x\n",
    "\\end{align}\n",
    "\n",
    "注意：导数是个向量。\n",
    "\n",
    "我们可以用矩阵运算，来替换掉上面的向量运算和累加。\n",
    "\n",
    "令有训练集$\\mathbf{X} = [x_0; x_1; \\dots; x_n]^T$，其中毎个样本长度为$m$，即有$x_0 = [x_0^0, x_0^1, \\dots, x_0^m]$。对应有标签集$y = [y_0, y_1, \\dots, y_n]^T$。\n",
    "\n",
    "令参数值$w$，矩阵乘法记为$\\times$，向量按元素相乘记为$\\cdot$，则可改写前面公式为：\n",
    "\n",
    "\\begin{align}\n",
    "  z &= \\exp \\left ( -y \\cdot (X \\times w) \\right ) \\\\\n",
    "  L(w) &= \\sum \\log (1 + z) \\\\\n",
    "  \\frac{\\partial L}{\\partial w} &= (-y \\cdot (1 - \\frac1{1 + z}))^T \\times X\n",
    "\\end{align}\n",
    "\n",
    "依上式写函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logit_loss_and_grad(w, X, y):\n",
    "    w = w[:, None] if len(w.shape) == 1 else w\n",
    "    \n",
    "    z = np.exp(np.multiply(-y, np.dot(X, w)))\n",
    "    loss = np.sum(np.log1p(z))\n",
    "    grad = np.dot((np.multiply(-y, (1 - 1 / (1 + z)))).T, X)\n",
    "    \n",
    "    return loss, grad.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 测试数据\n",
    "X = df[\"x\"].as_matrix()\n",
    "# 标签\n",
    "y = df[\"y\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初始权重值\n",
    "w0 = np.zeros(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532.33703467003795,\n",
       " array([  -652.   , -18928.5  ,  -9490.5  ,  -2970.   , -13445.   ,\n",
       "         -4709.1  ,    -73.767,  -4967.   ]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 演示一轮损失函数和导数值\n",
    "logit_loss_and_grad(w0, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02490757,  0.72310265,  0.36255412,  0.11345933,  0.51362311,\n",
       "        0.17989607,  0.00281803,  0.18974831])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调过数值寻优方法，求解得到w \n",
    "\n",
    "(w, loss, info) = sp.optimize.fmin_l_bfgs_b(logit_loss_and_grad, w0, args=(X, y))\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测概率值\n",
    "y_pred_probability = 1 / (1 + np.exp(np.multiply(-y, np.dot(X, w[:, None]))))\n",
    "# 预测结果\n",
    "y_pred = (y_pred_probability >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34895833333333331"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测准确度\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(y, y_pred_probability, reorder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，到此，就完成了二分类的演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. 多分类\n",
    "\n",
    "#### 2.0 基本原理\n",
    "\n",
    "前面讲到二分类借助的是logistic function，当问题推广到多分类时，自然而然想到就可借助[softmax functioin](https://en.wikipedia.org/wiki/Softmax_function)。\n",
    "\n",
    "> In mathematics, the softmax function, or normalized exponential function, is a generalization of the logistic function）$\\sigma (\\mathbf {z} )_{j}={\\frac {e^{z_{j}}}{\\sum _{k=1}^{K}e^{z_{k}}}}$\n",
    "\n",
    "可以看到softmax本身是很简单的形式，它要求给出模型预测值$e^{z_k}$，归一化作为概率值输出。所以只要指定这个$e^{z_k}$是线性模型$\\beta_0 + \\beta x$，问题就解决了。具体见下面。\n",
    "\n",
    "对于K分类问题，假设有样本$x$，标签$y \\in \\{0, 1, 2, ..., K - 1\\}$。我们将$y = 0$选为标杆，得到K-1个线性模型：\n",
    "\n",
    "\\begin{align}\n",
    "  \\log \\frac{P(y = 1 | x)}{P(y = 0 | x)} &= \\beta_{10} + \\beta_1 x \\\\\n",
    "  \\cdots \\\\\n",
    "  \\log \\frac{P(y = K - 1 | x)}{P(y = 0 | x)} &= \\beta_{(K-1)0} + \\beta_{K-1} x \\\\\n",
    "\\end{align}\n",
    "\n",
    "特别地，用同样的式子列写$y = 0$，可得到\n",
    "\n",
    "\\begin{align}\n",
    "  \\log \\frac{P(y = 0 | x)}{P(y = 0 | x)} &= \\log(1) \\\\\n",
    "    & = 0 \\\\\n",
    "    & = 0 + [0, 0, \\dots, 0] x \\\\\n",
    "    & = \\beta_{00} + \\beta_0 x \\quad \\text{令$\\beta_0$是零阵} \\\\\n",
    "\\end{align}\n",
    "\n",
    "也就是说，令$\\beta_0$是零阵，则可以将上面式子统一写为\n",
    "\n",
    "\\begin{equation}\n",
    "  \\log \\frac{P(y = k | x)}{P(y = 0 | x)} = \\beta_{k0} + \\beta_k x\n",
    "\\end{equation}\n",
    "\n",
    "即有 $P(y = k | x) = e^{\\beta_{k0} + \\beta_k} x P(y = 0 | x)$，   \n",
    "又概率相加总为1，$\\sum_k P(y = k | x) = 1$，两式联立可得:\n",
    "\n",
    "\\begin{equation}\n",
    "  P(y = k | x) = \\frac{e^{\\beta_{k0} + \\beta_k x}}{\\sum_i e^{\\beta_{i0} + \\beta_i x}}\n",
    "\\end{equation}\n",
    "\n",
    "我们希望模型参数$\\beta$使对应的$P(y | x, \\beta)$时越大越好，所以，可定义损失函数为\n",
    "\n",
    "\\begin{align}\n",
    "  L(\\beta) &= -log P(y = k | x, \\beta) \\\\\n",
    "    &= \\log(\\sum_i e^{\\beta_{i0} + \\beta_i x)} - (\\beta_{k0} + \\beta_k x)\n",
    "\\end{align}\n",
    "\n",
    "再求得一阶导数\n",
    "\n",
    "\\begin{align}\n",
    "  \\frac{\\partial L}{\\partial \\beta} &= \\frac1{\\sum_i e^{\\beta_{i0} + \\beta_i x} x} e^{\\beta_{k0} + \\beta_k x} - x I(y = k) \\\\\n",
    "    &= x \\left ( \\frac{e^{\\beta_{k0} + \\beta_k x}}{\\sum_i e^{\\beta_{i0} + \\beta_i x}} - I(y = k) \\right ) \\\\\n",
    "\\end{align}\n",
    "\n",
    "有了损失函数和一阶导数，同样地，可以使用数值优化法来寻优。上面的式子容易溢出，相应的变形见[逻辑回归在spark中的实现简介](./spark_ml_lr.ipynb)第2.2节。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 特例\n",
    "\n",
    "令$K=2$，代入多分类式子：\n",
    "\n",
    "\\begin{align}\n",
    "  P(y = 1 | x) &= \\frac{e^{\\beta_{k0} + \\beta_k x}}{\\sum_i e^{\\beta_{i0} + \\beta_i x}} |_{k = 1} \\\\\n",
    "    &= \\frac{e^{\\beta_{10} + \\beta_1 x}}{e^{\\beta_{00} + \\beta_0 x} + e^{\\beta_{10} + \\beta_1 x}}  \\\\\n",
    "    &= \\frac{e^{\\beta_{10} + \\beta_1 x}}{1 + e^{\\beta_{10} + \\beta_1 x}}  \\\\\n",
    "    &= \\frac1{1 + e^{- (\\beta_{10} + \\beta_1 x)}}  \\\\\n",
    "    &= \\frac1{1 + e^{- (w^T x + b)}}  \\\\\n",
    "\\end{align}\n",
    "\n",
    "可以看到，二分类逻辑回归只是多分类的特例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 小结\n",
    "\n",
    "本文简要介绍了逻辑回归二分类和多分类的理论表达式，并对二分类做了代码演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
